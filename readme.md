```
Python api for calling Chat With RTX local server

On my 4090
    mistral 110 tok/s
    lama 69 tok/s

Chat With RTX builds int4 (W4A16 AWQ) tensortRT engines for mistral 7b and llama2 13b

LICENSE: CC0
```
